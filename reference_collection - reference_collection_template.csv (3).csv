  ,Title ,Authors,Year,Journal,Publisher (IEEE/ACM/Elsevier/Springer),DOI,URL,Type (journal/conference/survey/experiment),,,,,BibTeX
0,Adversarial Machine Learning Attacks Against Network Intrusion Detection Systems: Classification Analysis,Dimitriya A. Mihaylova,2025,https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=11098254,IEEE,10.1109/ICEST66328.2025.11098254,,Confrence ,,,,,"@INPROCEEDINGS{11098254,
  author={Mihaylova, Dimitriya A.},
  booktitle={2025 60th International Scientific Conference on Information, Communication and Energy Systems and Technologies (ICEST)}, 
  title={Adversarial Machine Learning Attacks Against Network Intrusion Detection Systems: Classification Analysis}, 
  year={2025},
  volume={},
  number={},
  pages={1-4},
  keywords={Training;Hands;Machine learning algorithms;Network intrusion detection;Automated machine learning;Adversarial machine learning;Malware;Security;Protection;Testing;Adversarial Machine Learning;Network Intrusion Detection Systems;Poisoning attack;Evasion attack},
  doi={10.1109/ICEST66328.2025.11098254}}"
,Conditional Generative Adversarial Network with Optimal Machine Learning Based Intrusion Detection System,K. Hemavathi; R. Latha,2024,https://ieeexplore.ieee.org/document/10370325,IEEE, 10.1109/ICSCNA58489.2023.10370325,,Confrence ,,,,,"@INPROCEEDINGS{10370325,
  author={Hemavathi, K. and Latha, R.},
  booktitle={2023 International Conference on Sustainable Communication Networks and Application (ICSCNA)}, 
  title={Conditional Generative Adversarial Network with Optimal Machine Learning Based Intrusion Detection System}, 
  year={2023},
  volume={},
  number={},
  pages={1176-1182},
  keywords={Machine learning algorithms;Databases;Intrusion detection;Telecommunication traffic;Machine learning;Generative adversarial networks;Security;Machine learning;Feature selection;Class imbalance;CGAN;Intrusion detection system},
  doi={10.1109/ICSCNA58489.2023.10370325}}
"
,Application of Machine Learning Algorithms in Network Intrusion Detection,Shuchang Zhang; Yanling Li; Yu Shi; Man Hua,2022,https://ieeexplore.ieee.org/document/9778286,IEEE,10.1109/ICCCBDA55098.2022.9778286,,Confrence ,,,,,"@INPROCEEDINGS{9778286,
  author={Zhang, Shuchang and Li, Yanling and Shi, Yu and Hua, Man},
  booktitle={2022 7th International Conference on Cloud Computing and Big Data Analytics (ICCCBDA)}, 
  title={Application of Machine Learning Algorithms in Network Intrusion Detection}, 
  year={2022},
  volume={},
  number={},
  pages={464-471},
  keywords={Deep learning;Cloud computing;Machine learning algorithms;Intrusion detection;Cyberspace;Network intrusion detection;Big Data;cyber security;intrusion detection;machine learning;deep learning},
  doi={10.1109/ICCCBDA55098.2022.9778286}}
"
,Adversarial Challenges in Network Intrusion Detection Systems: Research Insights and Future Prospects,Sabrine Ennaji; Fabio de Gaspari; Dorjan Hitaj; Alicia Kbidi; Luigi Vincenzo Mancini,2025,https://ieeexplore.ieee.org/document/11131124,IEEE,10.1109/ACCESS.2025.3600984,,Journal,,,,,"@ARTICLE{11131124,
  author={Ennaji, Sabrine and de Gaspari, Fabio and Hitaj, Dorjan and Kbidi, Alicia and Vincenzo Mancini, Luigi},
  journal={IEEE Access}, 
  title={Adversarial Challenges in Network Intrusion Detection Systems: Research Insights and Future Prospects}, 
  year={2025},
  volume={13},
  number={},
  pages={148613-148645},
  keywords={Surveys;Network intrusion detection;Telecommunication traffic;Machine learning;Computer security;Semantics;Taxonomy;Deep learning;Artificial neural networks;Systematic literature review;Network intrusion detection systems;machine learning;cybersecurity;deep learning;adversarial attacks},
  doi={10.1109/ACCESS.2025.3600984}}"
,A Literature Review on Machine Learning Methods Used in Intrusion Detection System to Detect Cyber Attack,Aniruddha Prabhu B P; Sunitha N R,2024,https://ieeexplore.ieee.org/document/10803215,IEEE,10.1109/CYBERCOM63683.2024.10803215,,Confrence ,,,,,"@INPROCEEDINGS{10803215,
  author={B P, Aniruddha Prabhu and N R, Sunitha},
  booktitle={2024 International Conference on Cybernation and Computation (CYBERCOM)}, 
  title={A Literature Review on Machine Learning Methods Used in Intrusion Detection System to Detect Cyber Attack}, 
  year={2024},
  volume={},
  number={},
  pages={94-97},
  keywords={Support vector machines;Cloud computing;Computational modeling;Storage management;Intrusion detection;Machine learning;Real-time systems;Vectors;Internet of Things;Cyberattack;Intrusion detection system (IDS);Machine Learning (ML);Artificial Intelligence (AI);Cyber Security (CS);support vector machines (SVM)},
  doi={10.1109/CYBERCOM63683.2024.10803215}}
"
,A Technique for Protecting Machine Learning Components of Intrusion Detection Systems from Evasion Attacks,Egor Ichetovkin; Igor Kotenko,2025,https://ieeexplore.ieee.org/document/10986131,IEEE,10.1109/SmartIndustryCon65166.2025.10986131,,Confrence ,,,,,"@INPROCEEDINGS{10986131,
  author={Ichetovkin, Egor and Kotenko, Igor},
  booktitle={2025 International Russian Smart Industry Conference (SmartIndustryCon)}, 
  title={A Technique for Protecting Machine Learning Components of Intrusion Detection Systems from Evasion Attacks}, 
  year={2025},
  volume={},
  number={},
  pages={735-740},
  keywords={Measurement;Industries;Intrusion detection;Machine learning;Mathematical models;Protection;Long short term memory;Cyberattack;cybersecurity;intrusion detection systems;machine learning components;adversarial attacks;methods of protection},
  doi={10.1109/SmartIndustryCon65166.2025.10986131}}
"
,Clustering and Ensemble Based Approach for Securing Electricity Theft Detectors Against Evasion Attacks,Islam Elgarhy; Mahmoud M. Badr; Mohamed M. E. A. Mahmoud; Mostafa M. Fouda; Maazen Alsabaan; Hisham A. Kholidy,2023,https://ieeexplore.ieee.org/document/10258262,IEEE,10.1109/ACCESS.2023.3318111,,Confrence ,,,,,"@ARTICLE{10258262,
  author={Elgarhy, Islam and Badr, Mahmoud M. and Mahmoud, Mohamed M. E. A. and Fouda, Mostafa M. and Alsabaan, Maazen and Kholidy, Hisham A.},
  journal={IEEE Access}, 
  title={Clustering and Ensemble Based Approach for Securing Electricity Theft Detectors Against Evasion Attacks}, 
  year={2023},
  volume={11},
  number={},
  pages={112147-112164},
  keywords={Detectors;Robustness;Threat modeling;Support vector machines;Data models;Closed box;Benchmark testing;Smart grids;Machine learning;Clustering methods;Security;smart grids;electricity theft;evasion attacks;applied machine learning;clustering;ensemble},
  doi={10.1109/ACCESS.2023.3318111}}"
,Model Evasion Attack on Intrusion Detection Systems using Adversarial Machine Learning,Md. Ahsan Ayub; William A. Johnson; Douglas A. Talbert; Ambareen Siraj,2020,https://ieeexplore.ieee.org/document/9086268,IEEE,10.1109/CISS48834.2020.1570617116,,Confrence ,,,,,"@INPROCEEDINGS{9086268,
  author={Ayub, Md. Ahsan and Johnson, William A. and Talbert, Douglas A. and Siraj, Ambareen},
  booktitle={2020 54th Annual Conference on Information Sciences and Systems (CISS)}, 
  title={Model Evasion Attack on Intrusion Detection Systems using Adversarial Machine Learning}, 
  year={2020},
  volume={},
  number={},
  pages={1-6},
  keywords={Jacobian matrices;Machine learning algorithms;Perturbation methods;Intrusion detection;Multilayer perceptrons;Predictive models;Adversarial machine learning;Adversarial Machine Learning;Evasion Attack;Intrusion Detection System;Neural Network},
  doi={10.1109/CISS48834.2020.1570617116}}"
,"White-Box Adversarial Exploitation of NIDS: Insights from FGSM, PGD, and C&W",,2025,https://ieeexplore.ieee.org/document/109324055,IEEE, 10.1109/CICTN64563.2025.10932405,,Confrence ,,,,,"@INPROCEEDINGS{10932405,
  author={Ali, Uliya Ashfaque and Dogra, Krish and Sharma, Seema},
  booktitle={2025 2nd International Conference on Computational Intelligence, Communication Technology and Networking (CICTN)}, 
  title={White-Box Adversarial Exploitation of NIDS: Insights from FGSM, PGD, and C&W}, 
  year={2025},
  volume={},
  number={},
  pages={668-673},
  keywords={Measurement;Training;Accuracy;Computational modeling;Network intrusion detection;Telecommunication traffic;Machine learning;Data models;Robustness;Computer security;Network Intrusion Detection Systems (NIDS);adversarial attacks;CNN-LSTM;FGSM;PGD;Carlini & Wagner attack;robustness;network security},
  doi={10.1109/CICTN64563.2025.10932405}}"
,Projected Gradient Descent Adversarial Attack and Its Defense on a Fault Diagnosis System,Mustafa Sinasi Ayas; Selen Ayas; Seddik M. Djouadi,2022,https://ieeexplore.ieee.org/document/9851334,IEEE, 10.1109/TSP55681.2022.9851334,,Confrence ,,,,,"@INPROCEEDINGS{9851334,
  author={Ayas, Mustafa Sinasi and Ayas, Selen and Djouadi, Seddik M.},
  booktitle={2022 45th International Conference on Telecommunications and Signal Processing (TSP)}, 
  title={Projected Gradient Descent Adversarial Attack and Its Defense on a Fault Diagnosis System}, 
  year={2022},
  volume={},
  number={},
  pages={36-39},
  keywords={Fault diagnosis;Training;Analytical models;Perturbation methods;Knowledge based systems;Force;Rolling bearings;Fault diagnosis system;adversarial machine learning;projected gradient descent;adversarial training},
  doi={10.1109/TSP55681.2022.9851334}}
"
,Adversarial attacks for speaker recognition system with FGSM-CNN and FGSM-DNN,Mokdad Yacine Abdelhakim; Debyeche Mohamed Krobba Ahmed,2025,https://ieeexplore.ieee.org/document/10894089,IEEE,10.1109/ICTIS62692.2024.10894089,,Confrence ,,,,,"@INPROCEEDINGS{10894089,
  author={Abdelhakim, Mokdad Yacine and Krobba Ahmed, Debyeche Mohamed},
  booktitle={2024 International Conference on Telecommunications and Intelligent Systems (ICTIS)}, 
  title={Adversarial attacks for speaker recognition system with FGSM-CNN and FGSM-DNN}, 
  year={2024},
  volume={},
  number={},
  pages={1-6},
  keywords={Threat modeling;Performance evaluation;Error analysis;Personal voice assistants;Speaker recognition;Psychoacoustic models;Telecommunications;Security;Convolutional neural networks;Speech processing;Adversarial attacks;speaker recognition;FGSM;CNN;DNN;IBM;EER;PLDA;Cosine},
  doi={10.1109/ICTIS62692.2024.10894089}}"
,Intrusion Detection Classification Method based on Generative Adversarial Networks,Yan Lu,2023,https://ieeexplore.ieee.org/document/10229791,IEEE,10.1109/ICFEICT59519.2023.00064,,Confrence ,,,,,"@INPROCEEDINGS{10229791,
  author={Lu, Yan},
  booktitle={2023 3rd International Conference on Frontiers of Electronics, Information and Computation Technologies (ICFEICT)}, 
  title={Intrusion Detection Classification Method based on Generative Adversarial Networks}, 
  year={2023},
  volume={},
  number={},
  pages={344-349},
  keywords={Training;Deep learning;Intrusion detection;Training data;Network intrusion detection;Network security;Generative adversarial networks;Deep learning;Generate adversarial networks;Intrusion detection},
  doi={10.1109/ICFEICT59519.2023.00064}}
"
,PPATF: A Privacy-Preserving Adversarial Training Framework to Enhance the Robustness of Lightweight Intrusion Detection Models,Wonjun Han; Soojin Lee,2025,https://ieeexplore.ieee.org/document/11263865,IEEE,10.1109/ACCESS.2025.3635667,,Journal,,,,,"@ARTICLE{11263865,
  author={Han, Wonjun and Lee, Soojin},
  journal={IEEE Access}, 
  title={PPATF: A Privacy-Preserving Adversarial Training Framework to Enhance the Robustness of Lightweight Intrusion Detection Models}, 
  year={2025},
  volume={13},
  number={},
  pages={199227-199246},
  keywords={Training;Robustness;Data models;Computational modeling;Intrusion detection;Accuracy;Smoothing methods;Training data;Feature extraction;Computational efficiency;Intrusion detection;adversarial training;data smoothing;differential privacy;model ensemble;lightweight model design},
  doi={10.1109/ACCESS.2025.3635667}}
"
,Improving the Robustness of DNNs-based Network Intrusion Detection Systems through Adversarial Training,Eufemia Lella; Nicola Macchiarulo; Andrea Pazienza; Domenico Lofù; Agostino Abbatecola; Pietro Noviello,2023,https://ieeexplore.ieee.org/document/10193009,IEEE,10.23919/SpliTech58164.2023.10193009,,Confrence ,,,,,"@INPROCEEDINGS{10193009,
  author={Lella, Eufemia and Macchiarulo, Nicola and Pazienza, Andrea and Lofù, Domenico and Abbatecola, Agostino and Noviello, Pietro},
  booktitle={2023 8th International Conference on Smart and Sustainable Technologies (SpliTech)}, 
  title={Improving the Robustness of DNNs-based Network Intrusion Detection Systems through Adversarial Training}, 
  year={2023},
  volume={},
  number={},
  pages={1-6},
  keywords={Training;Deep learning;System performance;Network intrusion detection;Telecommunication traffic;Robustness;Ransomware;Network Intrusion Detection Systems;Adversarial Attacks;Deep Learning;Adversarial Training;Cybersecurity},
  doi={10.23919/SpliTech58164.2023.10193009}}
"
,Assessing adversarial training effect on IDSs and GANs,Hassan Chaitou; Thomas Robert; Jean Leneutre; Laurent Pautet,2021,https://ieeexplore.ieee.org/document/9527949,IEEE,10.1109/CSR51186.2021.9527949,,Confrence ,,,,,"@INPROCEEDINGS{9527949,
  author={Chaitou, Hassan and Robert, Thomas and Leneutre, Jean and Pautet, Laurent},
  booktitle={2021 IEEE International Conference on Cyber Security and Resilience (CSR)}, 
  title={Assessing adversarial training effect on IDSs and GANs}, 
  year={2021},
  volume={},
  number={},
  pages={543-550},
  keywords={Training;Sociology;Intrusion detection;Telecommunication traffic;Generators;Robustness;Frequency measurement;Adversarial machine learning;GAN;Intrusion Detection System;Sensitivity analysis},
  doi={10.1109/CSR51186.2021.9527949}}
"
,Assessing the Resilience of Automotive Intrusion Detection Systems to Adversarial Manipulation,"Stefano Longari, Paolo Cerracchio, Michele Carminati, Stefano Zanero",2025,https://dl.acm.org/doi/10.1145/3737294,ACM ,10.1145/3737294,,Journal,,,,,"@article{10.1145/3737294,
author = {Longari, Stefano and Cerracchio, Paolo and Carminati, Michele and Zanero, Stefano},
title = {Assessing the Resilience of Automotive Intrusion Detection Systems to Adversarial Manipulation},
year = {2025},
issue_date = {July 2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {9},
number = {3},
issn = {2378-962X},
url = {https://doi.org/10.1145/3737294},
doi = {10.1145/3737294},
abstract = {The security of modern vehicles has become increasingly important, with the controller area network (CAN) bus serving as a critical communication backbone for various electronic control units (ECUs). The absence of robust security measures in CAN, coupled with the increasing connectivity of vehicles, makes them susceptible to cyberattacks. While intrusion detection systems (IDSs) have been developed to counter such threats, they are not foolproof. Adversarial attacks, particularly evasion attacks, can manipulate inputs to bypass detection by IDSs. This article extends our previous work by investigating the feasibility and impact of gradient-based adversarial attacks performed with different degrees of knowledge against automotive IDSs. We consider three scenarios: white-box (attacker with full system knowledge), grey-box (partial system knowledge), and—the more realistic—black-box (no knowledge of the IDS’s internal workings or data). We evaluate the effectiveness of the proposed attacks against state-of-the-art IDSs on two publicly available datasets. Additionally, we study the effect of the adversarial perturbation on the attack impact and evaluate real-time feasibility by precomputing evasive payloads for timed injection based on bus traffic. Our results demonstrate that, besides attacks being challenging due to the automotive domain constraints, their effectiveness is strongly dependent on the dataset quality, the target IDS, and the attacker’s degree of knowledge.},
journal = {ACM Trans. Cyber-Phys. Syst.},
month = aug,
articleno = {31},
numpages = {27},
keywords = {Automotive Security, Intrusion Detection Systems, Evasion Attacks}
}"
,Modeling Realistic Adversarial Attacks against Network Intrusion Detection Systems,"Giovanni Apruzzese, Mauro Andreolini, Luca Ferretti, Mirco Marchetti, Michele Colajanni",2022,https://dl.acm.org/doi/10.1145/3469659,ACM ,,,Journal,,,,,"@article{10.1145/3469659,
author = {Apruzzese, Giovanni and Andreolini, Mauro and Ferretti, Luca and Marchetti, Mirco and Colajanni, Michele},
title = {Modeling Realistic Adversarial Attacks against Network Intrusion Detection Systems},
year = {2022},
issue_date = {September 2022},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {3},
number = {3},
url = {https://doi.org/10.1145/3469659},
doi = {10.1145/3469659},
abstract = {The incremental diffusion of machine learning algorithms in supporting cybersecurity is creating novel defensive opportunities but also new types of risks. Multiple researches have shown that machine learning methods are vulnerable to adversarial attacks that create tiny perturbations aimed at decreasing the effectiveness of detecting threats. We observe that existing literature assumes threat models that are inappropriate for realistic cybersecurity scenarios, because they consider opponents with complete knowledge about the cyber detector or that can freely interact with the target systems. By focusing on Network Intrusion Detection Systems based on machine learning, we identify and model the real capabilities and circumstances required by attackers to carry out feasible and successful adversarial attacks. We then apply our model to several adversarial attacks proposed in literature and highlight the limits and merits that can result in actual adversarial attacks. The contributions of this article can help hardening defensive systems by letting cyber defenders address the most critical and real issues and can benefit researchers by allowing them to devise novel forms of adversarial attacks based on realistic threat models.},
journal = {Digital Threats},
month = feb,
articleno = {31},
numpages = {19},
keywords = {NIDS, evasion, adversarial attacks, network intrusion detection, Cybersecurity}
}"
,Intrusion Detection Based on Federated Learning: A Systematic Review,"Jose Luis Hernandez-Ramos, Georgios Karopoulos, Efstratios Chatzoglou, Vasileios Kouliaridis, Enrique Marmol, Aurora Gonzalez-Vidal, Georgios KambourakisAuthors",2025,https://dl.acm.org/doi/10.1145/3731596,ACM ,,,Survey ,,,,,"@article{10.1145/3731596,
author = {Hernandez-Ramos, Jose Luis and Karopoulos, Georgios and Chatzoglou, Efstratios and Kouliaridis, Vasileios and Marmol, Enrique and Gonzalez-Vidal, Aurora and Kambourakis, Georgios},
title = {Intrusion Detection Based on Federated Learning: A Systematic Review},
year = {2025},
issue_date = {December 2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {57},
number = {12},
issn = {0360-0300},
url = {https://doi.org/10.1145/3731596},
doi = {10.1145/3731596},
abstract = {The evolution of cybersecurity is closely linked to the development and improvement of artificial intelligence (AI). As a key tool for realizing more cybersecure ecosystems, Intrusion Detection Systems (IDSs) have evolved tremendously in recent years by integrating machine learning (ML) techniques to detect increasingly sophisticated cybersecurity attacks hidden in big data. However, traditional approaches rely on centralized learning, in which data from end nodes are shared with data centers for analysis. Recently, the application of federated learning (FL) in this context has attracted great interest to come up with collaborative intrusion detection approaches where data does not need to be shared. Due to the recent rise of this field, this work presents a complete, contemporary taxonomy for FL-enabled IDS approaches that stems from a comprehensive survey of the literature from 2018 to 2022. Precisely, our discussion includes an analysis of the main ML models, datasets, aggregation functions, as well as implementation libraries employed by the proposed FL-enabled IDS approaches. On top of everything else, we provide a critical view of the current state of the research around this topic, and describe the main challenges and future directions based on the analysis of the literature and our own experience in this area.},
journal = {ACM Comput. Surv.},
month = jul,
articleno = {309},
numpages = {65},
keywords = {Federated Learning, Intrusion Detection Systems, Cybersecurity, Machine Learning, Taxonomy, Aggregation Methods, Distributed Intelligence}
}"
,Federated Learning-based Information Leakage Risk Detection for Secure Medical Internet of Things,"Tingting Wang, Tao Tang, Zhen Cai, Kai Fang, Jinyu Tian, Jianqing Li, Wei Wang, Feng Xia",2024,https://dl.acm.org/doi/10.1145/3639466,ACM ,,,Journal,,,,,"@article{10.1145/3639466,
author = {Wang, Tingting and Tang, Tao and Cai, Zhen and Fang, Kai and Tian, Jinyu and Li, Jianqing and Wang, Wei and Xia, Feng},
title = {Federated Learning-based Information Leakage Risk Detection for Secure Medical Internet of Things},
year = {2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
issn = {1533-5399},
url = {https://doi.org/10.1145/3639466},
doi = {10.1145/3639466},
abstract = {The Medical Internet of Things (MIoT) requires extreme information and communication security, particularly for remote consultation systems. MIoT’s integration of physical and computational components creates a seamless network of medical devices providing high-quality care via continuous monitoring and treatment. However, traditional security methods such as cryptography cannot prevent privacy compromise and information leakage caused by security breaches. To solve this issue, this paper proposes a novel Federated Learning Intrusion Detection System (FLIDS). FLIDS combines Generative Adversarial Network (GAN) and Federated Learning (FL) to detect cyber attacks like Denial of Service (DoS), data modification, and data injection using machine learning. FLIDS shows exceptional performance with over 99\% detection accuracy and 1\% False Positive Rate (FPR). It saves bandwidth by transmitting 3.8 times fewer bytes compared to central data collection. These results prove FLIDS’ effectiveness in detecting and mitigating security threats in Medical Cyber-Physical Systems (MCPS). The paper recommends scaling up FLIDS to use computing resources from multiple mobile devices for better intrusion detection accuracy and efficiency while reducing the burden on individual devices in MIoT.},
note = {Just Accepted},
journal = {ACM Trans. Internet Technol.},
month = jan,
keywords = {Patient Data., False Positive Rate, Training Accuracy, Dataset Construction, Discriminator Network, Data Leakage, GAN-based Privacy Protection, Medical Internet of Things, Intrusion Detection System, Federated Learning}
}"
,Towards realistic problem-space adversarial attacks against machine learning in network intrusion detection,"Marta Catillo, Antonio Pecchia, Antonio Repola, Umberto Villano",2024,https://dl.acm.org/doi/10.1145/3664476.3669974,ACM ,,,,,,,,"@inproceedings{10.1145/3664476.3669974,
author = {Catillo, Marta and Pecchia, Antonio and Repola, Antonio and Villano, Umberto},
title = {Towards realistic problem-space adversarial attacks against machine learning in network intrusion detection},
year = {2024},
isbn = {9798400717185},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3664476.3669974},
doi = {10.1145/3664476.3669974},
abstract = {Current trends in network intrusion detection systems (NIDS) capitalize on the extraction of features from network traffic and the use of up-to-date machine and deep learning techniques to infer a detection model; in consequence, NIDS can be vulnerable to adversarial attacks. Differently from the plethora of contributions that apply (and misuse) feature-level attacks envisioned in application domains far from NIDS, this paper proposes a novel approach to adversarial attacks, which consists in a realistic problem-space perturbation of the network traffic. The perturbation is achieved through a traffic control utility. Experiments are based on normal and Denial of Service traffic in both legitimate and adversarial conditions, and the application of four popular techniques to learn the NIDS models. The results highlight the transferability of the adversarial examples generated by the proposed problem-space attack as well as the effectiveness at inducing traffic misclassifications across the NIDS models obtained.},
booktitle = {Proceedings of the 19th International Conference on Availability, Reliability and Security},
articleno = {113},
numpages = {8},
keywords = {Denial of Service, adversarial examples, intrusion detection, machine learning, supervised learning},
location = {Vienna, Austria},
series = {ARES '24}
}"
,CodingCare: AI Code Generation Security Framework for Common Vulnerability Mitigation,"Zhiguo Ding, Songyang Wu, Yilin Zhang, Tao Yang, Yingna Li, Zhuhua Li, Hang Shao, Yicong Shi",2025,https://dl.acm.org/doi/10.1145/3732945.3732990,ACM ,,,,,,,,"@inproceedings{10.1145/3732945.3732990,
author = {Ding, Zhiguo and Wu, Songyang and Zhang, Yilin and Yang, Tao and Li, Yingna and Li, Zhuhua and Shao, Hang and Shi, Yicong},
title = {CodingCare: AI Code Generation Security Framework for Common Vulnerability Mitigation},
year = {2025},
isbn = {9798400715204},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3732945.3732990},
doi = {10.1145/3732945.3732990},
abstract = {This article provides a comprehensive review of code generation LLMs (Large Language Models) focusing on security issues and possible solutions to software development workflows. Recent literature suggests that more than 70\% of developers are using AI programming assistants in their day-to-day activities. Code generated by AI contains a plethora of serious vulnerabilities such as Cross-site scripting (XSS), SQL injection vulnerabilities, and unsafe credentials which impact the overall security of software systems. Most of the research, thus far, has focused on either the fine-tuning of larger models, working with the methods for optimal prompting, or looking at security evaluations to detect outcomes in coding LLMs, rather than exploring generative models with an overall design of a security framework. To contribute, we develop an overall security framework for code LLMs including prompt libraries, bibliography databases, vulnerability databases, repositories of programming use-cases for several ways through the software development life-cycles, including requirement analysis, code development, code vetting changes, code iteration, and code submission. We developed an experimental system and we will use it to conduct comparative experiments with three code LLMs including Deepseek-coder-7B, Mistral-7B, and Code Llama-7B. The results of this research indicate that our proposed security framework reduces the number of CVEs reported. This research lays a groundwork for projects that lead to other research issues related to software security LLMs considerations.},
booktitle = {Proceedings of the 2025 4th International Conference on Intelligent Systems, Communications and Computer Networks},
pages = {307–312},
numpages = {6},
keywords = {AI code generation, Common vulnerability, Large language model, Security framework},
location = {
},
series = {ISCCN '25}
}"
,LAMPS '25: ACM CCS Workshop on Large AI Systems and Models with Privacy and Security Analysis,"Kwok-Yan Lam, Xiaoning Liu, Derui Wang, Bo Li, Wenyuan Xu, Jieshan Chen, Minhui Xue, Xingliang Yuan, Guangdong Bai, Shuo Wang",2025,https://dl.acm.org/doi/10.1145/3719027.3767670,ACM ,,,,,,,,"@inproceedings{10.1145/3719027.3767670,
author = {Lam, Kwok-Yan and Liu, Xiaoning and Wang, Derui and Li, Bo and Xu, Wenyuan and Chen, Jieshan and Xue, Minhui and Yuan, Xingliang and Bai, Guangdong and Wang, Shuo},
title = {LAMPS '25: ACM CCS Workshop on Large AI Systems and Models with Privacy and Security Analysis},
year = {2025},
isbn = {9798400715259},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3719027.3767670},
doi = {10.1145/3719027.3767670},
abstract = {With large AI systems and models (LAMs) playing an ever-growing role across diverse applications, their impact on the privacy and cybersecurity of critical infrastructure has become a pressing concern. The LAMPS workshop is dedicated to tackling these emerging challenges, promoting dialogue on cutting-edge developments and ethical issues in safeguarding LAMs within critical infrastructure contexts. Bringing together leading experts from around the world, this workshop will delve into the complex privacy and cybersecurity risks posed by LAMs in critical sectors. Attendees will explore innovative solutions, exchange best practices, and contribute to shaping the future research agenda, emphasizing the crucial balance between advancing AI technologies and securing critical digital and physical infrastructures.},
booktitle = {Proceedings of the 2025 ACM SIGSAC Conference on Computer and Communications Security},
pages = {4914–4915},
numpages = {2},
keywords = {ai systems and models, critical infrastructure, privacy, security},
location = {Taipei, Taiwan},
series = {CCS '25}
}"
,Adversarial Attacks and Defenses in Deep Learning: From a Perspective of Cybersecurity,"Shuai Zhou, Chi Liu, Dayong Ye, Tianqing Zhu, Wanlei Zhou, Philip S. Yu",2022,https://dl.acm.org/doi/10.1145/3547330,ACM ,,,,,,,,"@article{10.1145/3547330,
author = {Zhou, Shuai and Liu, Chi and Ye, Dayong and Zhu, Tianqing and Zhou, Wanlei and Yu, Philip S.},
title = {Adversarial Attacks and Defenses in Deep Learning: From a Perspective of Cybersecurity},
year = {2022},
issue_date = {August 2023},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {55},
number = {8},
issn = {0360-0300},
url = {https://doi.org/10.1145/3547330},
doi = {10.1145/3547330},
abstract = {The outstanding performance of deep neural networks has promoted deep learning applications in a broad set of domains. However, the potential risks caused by adversarial samples have hindered the large-scale deployment of deep learning. In these scenarios, adversarial perturbations, imperceptible to human eyes, significantly decrease the model’s final performance. Many papers have been published on adversarial attacks and their countermeasures in the realm of deep learning. Most focus on evasion attacks, where the adversarial examples are found at test time, as opposed to poisoning attacks where poisoned data is inserted into the training data. Further, it is difficult to evaluate the real threat of adversarial attacks or the robustness of a deep learning model, as there are no standard evaluation methods. Hence, with this article, we review the literature to date. Additionally, we attempt to offer the first analysis framework for a systematic understanding of adversarial attacks. The framework is built from the perspective of cybersecurity to provide a lifecycle for adversarial attacks and defenses.},
journal = {ACM Comput. Surv.},
month = dec,
articleno = {163},
numpages = {39},
keywords = {advanced persistent threats, cybersecurity, adversarial attacks and defenses, Deep learning}
}"
,Arms Race in Adversarial Malware Detection: A Survey,"Deqiang Li, Qianmu Li, Yanfang (Fanny) Ye, Shouhuai Xu",2021,https://dl.acm.org/doi/10.1145/3484491,ACM ,,,,,,,,"@article{10.1145/3484491,
author = {Li, Deqiang and Li, Qianmu and Ye, Yanfang (Fanny) and Xu, Shouhuai},
title = {Arms Race in Adversarial Malware Detection: A Survey},
year = {2021},
issue_date = {January 2023},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {55},
number = {1},
issn = {0360-0300},
url = {https://doi.org/10.1145/3484491},
doi = {10.1145/3484491},
abstract = {Malicious software (malware) is a major cyber threat that has to be tackled with Machine Learning (ML) techniques because millions of new malware examples are injected into cyberspace on a daily basis. However, ML is vulnerable to attacks known as adversarial examples. In this article, we survey and systematize the field of Adversarial Malware Detection (AMD) through the lens of a unified conceptual framework of assumptions, attacks, defenses, and security properties. This not only leads us to map attacks and defenses to partial order structures, but also allows us to clearly describe the attack-defense arms race in the AMD context. We draw a number of insights, including: knowing the defender’s feature set is critical to the success of transfer attacks; the effectiveness of practical evasion attacks largely depends on the attacker’s freedom in conducting manipulations in the problem space; knowing the attacker’s manipulation set is critical to the defender’s success; and the effectiveness of adversarial training depends on the defender’s capability in identifying the most powerful attack. We also discuss a number of future research directions.},
journal = {ACM Comput. Surv.},
month = nov,
articleno = {15},
numpages = {35},
keywords = {poisoning attacks, evasion attacks, adversarial machine learning, Malware detection}
}"
,MAB-Malware: A Reinforcement Learning Framework for Blackbox Generation of Adversarial Malware,"Wei Song, Xuezixiang Li, Sadia Afroz, Deepali Garg, Dmitry Kuznetsov, Heng Yin",2022,https://dl.acm.org/doi/10.1145/3488932.3497768,ACM ,,,,,,,,"@inproceedings{10.1145/3488932.3497768,
author = {Song, Wei and Li, Xuezixiang and Afroz, Sadia and Garg, Deepali and Kuznetsov, Dmitry and Yin, Heng},
title = {MAB-Malware: A Reinforcement Learning Framework for Blackbox Generation of Adversarial Malware},
year = {2022},
isbn = {9781450391405},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3488932.3497768},
doi = {10.1145/3488932.3497768},
abstract = {Modern commercial antivirus systems increasingly rely on machine learning (ML) to keep up with the rampant inflation of new malware. However, it is well-known that machine learning models are vulnerable to adversarial examples (AEs). Previous works have shown that ML malware classifiers are fragile to the white-box adversarial attacks. However, ML models used in commercial antivirus (AV) products are usually not available to attackers and only return hard classification labels. Therefore, it is more practical to evaluate the robustness of ML models and real-world AVs in a pure black-box manner. We propose a black-box Reinforcement Learning (RL) based framework to generate AEs for PE malware classifiers and AV engines. It regards the adversarial attack problem as a multi-armed bandit problem, which finds an optimal balance between exploiting the successful patterns and exploring more varieties. Compared to other frameworks, our improvements lie in three points: 1) limiting the exploration space by modeling the generation process as a stateless process to avoid combination explosions, 2) reusing the successful payload in modeling; and 3) minimizing the changes on AE samples to correctly assign the rewards in RL learning (which also helps identify the root cause of evasions). As a result, our framework has much higher evasion rates than other off-the-shelf frameworks. Results show it has over 74\%--97\% evasion rate for two state-of-the-art ML detectors and over 32\%--48\% evasion rate for commercial AVs in a pure black-box setting. We also demonstrate that the transferability of adversarial attacks among ML-based classifiers is higher than that between ML-based classifiers and commercial AVs.},
booktitle = {Proceedings of the 2022 ACM on Asia Conference on Computer and Communications Security},
pages = {990–1003},
numpages = {14},
keywords = {adversarial learning, malware classification, reinforcement learning},
location = {Nagasaki, Japan},
series = {ASIA CCS '22}
}"
,Robustness and Cybersecurity in the EU Artificial Intelligence Act,"Henrik Nolte, Miriam Rateike, Michèle Finck",2025,https://dl.acm.org/doi/10.1145/3715275.3732020,ACM ,,,,,,,,"@inproceedings{10.1145/3715275.3732020,
author = {Nolte, Henrik and Rateike, Miriam and Finck, Mich\`{e}le},
title = {Robustness and Cybersecurity in the EU Artificial Intelligence Act},
year = {2025},
isbn = {9798400714825},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3715275.3732020},
doi = {10.1145/3715275.3732020},
abstract = {The EU Artificial Intelligence Act (AIA) establishes different legal principles for different types of AI systems. While prior work has sought to clarify some of these principles, little attention has been paid to robustness and cybersecurity. This paper aims to fill this gap. We identify legal challenges and shortcomings in provisions related to robustness and cybersecurity for high-risk AI systems (Art.&nbsp;15&nbsp;AIA) and general-purpose AI models (Art.&nbsp;55&nbsp;AIA). We show that robustness and cybersecurity demand resilience against performance disruptions. Furthermore, we assess potential challenges in implementing these provisions in light of recent advancements in the machine learning (ML) literature. Our analysis informs efforts to develop harmonized standards, guidelines by the European Commission, as well as benchmarks and measurement methodologies under Art.&nbsp;15(2)&nbsp;AIA. With this, we seek to bridge the gap between legal terminology and ML research, fostering a better alignment between research and implementation efforts.},
booktitle = {Proceedings of the 2025 ACM Conference on Fairness, Accountability, and Transparency},
pages = {283–295},
numpages = {13},
keywords = {Robustness, Cybersecurity, AIA, Regulation, European Union, EU law},
location = {
},
series = {FAccT '25}
}"
,,,,,,,,,,,,,
,,,,,,,,,,,,,
,,,,,,,,,,,,,
,	Investigating the impact of feature selection on adversarial transferability in intrusion detection system		2025	https://dl.acm.org/doi/10.1145/3715275.3732020	Elsevier,,2025,https://www.sciencedirect.com/science/article/abs/pii/S0167404825000161,Elsevier,,,,,,,,"@article{ADEKE2025104327,
title = {Investigating the impact of feature selection on adversarial transferability in intrusion detection system},
journal = {Computers & Security},
volume = {151},
pages = {104327},
year = {2025},
issn = {0167-4048},
doi = {https://doi.org/10.1016/j.cose.2025.104327},
url = {https://www.sciencedirect.com/science/article/pii/S0167404825000161},
author = {James Msughter Adeke and Guangjie Liu and Lord Amoah and Ogonna Joshua Nwali},
keywords = {Adversarial attack, Transferability, Feature selection, Intrusion detection system, Black-box attack, Machine learning},
abstract = {Adversarial attacks pose a serious threat to cybersecurity systems, particularly intrusion detection systems (IDSs). The property of transferability exacerbates this threat, as attacks designed to fool one IDS model can often fool others in black-box settings. Despite significant efforts to mitigate this property, the impact of feature selection on attack transferability remains unknown. This study investigates adversarial transferability across various machine learning (ML) and deep learning (DL) models used in IDSs. Two transferability scenarios are investigated: inter-model and intra-model transferability. We trained multiple IDS models, including support vector machine (SVM), random forest (RF), decision tree (DT), logistic regression (LR), and deep neural networks (DNNs) with different architectures, on feature subsets from various techniques. These IDS models are then subjected to a black-box attack using the zeroth-order optimization (ZOO) method. With the IoT-23 and UNSW-NB15 datasets, we evaluated transferability across different IDS models and feature subsets. The results show significant variations in transferability, with certain feature subsets notably reducing the attack success rate (ASR). Specifically, we recorded a reduction in ASR ranging from 99.9% to 0% depending on the feature subset and the target IDS model. These findings highlight the impact of feature selection on disrupting attack transferability, and suggest that IDS models trained with appropriate feature subsets are more robust to adversarial transferability.}
}"
,NIDS-Vis: Improving the generalized adversarial robustness of network intrusion detection system,,2024,https://www.sciencedirect.com/science/article/pii/S016740482400333X,Elsevier,,,,,,,,"@article{HE2024104028,
title = {NIDS-Vis: Improving the generalized adversarial robustness of network intrusion detection system},
journal = {Computers & Security},
volume = {145},
pages = {104028},
year = {2024},
issn = {0167-4048},
doi = {https://doi.org/10.1016/j.cose.2024.104028},
url = {https://www.sciencedirect.com/science/article/pii/S016740482400333X},
author = {Ke He and Dan Dongseong Kim and Muhammad Rizwan Asghar},
keywords = {Adversarial robustness, Anomaly detection, Decision boundary visualization, Deep learning, Network intrusion detection},
abstract = {Network Intrusion Detection Systems (NIDSes) are crucial for securing various networks from malicious attacks. Recent developments in Deep Neural Networks (DNNs) have encouraged researchers to incorporate DNNs as the underlying detection engine for NIDS. However, DNNs are susceptible to adversarial attacks, where subtle modifications to input data result in misclassification, posing a significant threat to security-sensitive domains such as NIDS. Existing efforts in adversarial defenses predominantly focus on supervised classification tasks in Computer Vision, differing substantially from the unsupervised outlier detection tasks in NIDS. To bridge this gap, we introduce a novel method of generalized adversarial robustness and present NIDS-Vis, an innovative black-box algorithm that traverses the decision boundary of DNN-based NIDSes near given inputs. Through NIDS-Vis, we can visualize the geometry of the decision boundaries and examine their impact on performance and adversarial robustness. Our experiment uncovers a tradeoff between performance and robustness, and we propose two novel training techniques, feature space partition and distributional loss function, to enhance the generalized adversarial robustness of DNN-based NIDSes without significantly compromising performance.}
}"
,Towards Detection of Network Anomalies using Machine Learning Algorithms on the NSL-KDD Benchmark Datasets,,2024,https://www.sciencedirect.com/science/article/pii/S1877050924006458,Elsevier,,,,,,,,"@article{VIBHUTE2024960,
title = {Towards Detection of Network Anomalies using Machine Learning Algorithms on the NSL-KDD Benchmark Datasets},
journal = {Procedia Computer Science},
volume = {233},
pages = {960-969},
year = {2024},
note = {5th International Conference on Innovative Data Communication Technologies and Application (ICIDCA 2024)},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2024.03.285},
url = {https://www.sciencedirect.com/science/article/pii/S1877050924006458},
author = {Amol D. Vibhute and Chandrashekhar H. Patil and Arjun V. Mane and Karbhari V. Kale},
keywords = {Random forest model, Cyber-attacks, Network anomaly detection, AUC-ROC curves, One-hot encoding method, K-nearest neighbours},
abstract = {In the present era, everyone is connected via the Internet for sharing digital information. The digital data is stored using the cloud technology. However, cloud technology is speedily increasing the volume of digital information and network intrusions. In this case, safeguarding the cloud data is essential for several purposes. Therefore, the present study emphasizes developing the network intrusion detection system using the benchmark NSL-KDD datasets. The ensemble learning-enabled random forest algorithm was proposed and implemented to select the most suitable features. The network intrusion detection and classification have been done using three machine learning models: support vector machine (SVM), logistic regression, and K-nearest neighbour's (KNN) with 87.58, 88.86, and 98.24% validation accuracies. Thus, the present study approach can be used in real-time cyber-attack detection and monitoring.}
}"
,Robust Network Security: A Deep Learning Approach to Intrusion Detection in IoT,"Ammar Odeh, Anas Abu Taleb",2024,https://www.sciencedirect.com/org/science/article/pii/S1546221824008622,Elsevier,,,,,,,,"@article{ODEH20244149,
title = {Robust Network Security: A Deep Learning Approach to Intrusion Detection in IoT},
journal = {Computers, Materials and Continua},
volume = {81},
number = {3},
pages = {4149-4169},
year = {2024},
issn = {1546-2218},
doi = {https://doi.org/10.32604/cmc.2024.058052},
url = {https://www.sciencedirect.com/science/article/pii/S1546221824008622},
author = {Ammar Odeh and Anas Abu Taleb},
keywords = {Intrusion detection system (IDS), Internet of Things (IoT), convolutional neural network (CNN), long short-term memory (LSTM), autoencoder, network security, deep learning, data preprocessing, feature selection, cyber threats},
abstract = {The proliferation of Internet of Things (IoT) technology has exponentially increased the number of devices interconnected over networks, thereby escalating the potential vectors for cybersecurity threats. In response, this study rigorously applies and evaluates deep learning models—namely Convolutional Neural Networks (CNN), Autoencoders, and Long Short-Term Memory (LSTM) networks—to engineer an advanced Intrusion Detection System (IDS) specifically designed for IoT environments. Utilizing the comprehensive UNSW-NB15 dataset, which encompasses 49 distinct features representing varied network traffic characteristics, our methodology focused on meticulous data preprocessing including cleaning, normalization, and strategic feature selection to enhance model performance. A robust comparative analysis highlights the CNN model’s outstanding performance, achieving an accuracy of 99.89%, precision of 99.90%, recall of 99.88%, and an F1 score of 99.89% in binary classification tasks, outperforming other evaluated models significantly. These results not only confirm the superior detection capabilities of CNNs in distinguishing between benign and malicious network activities but also illustrate the model’s effectiveness in multiclass classification tasks, addressing various attack vectors prevalent in IoT setups. The empirical findings from this research demonstrate deep learning’s transformative potential in fortifying network security infrastructures against sophisticated cyber threats, providing a scalable, high-performance solution that enhances security measures across increasingly complex IoT ecosystems. This study’s outcomes are critical for security practitioners and researchers focusing on the next generation of cyber defense mechanisms, offering a data-driven foundation for future advancements in IoT security strategies.}
}"
,A sequential deep learning framework for a robust and resilient network intrusion detection system,,2024,https://www.sciencedirect.com/science/article/pii/S0167404824002311,Elsevier,,,,,,,,"@article{HORE2024103928,
title = {A sequential deep learning framework for a robust and resilient network intrusion detection system},
journal = {Computers & Security},
volume = {144},
pages = {103928},
year = {2024},
issn = {0167-4048},
doi = {https://doi.org/10.1016/j.cose.2024.103928},
url = {https://www.sciencedirect.com/science/article/pii/S0167404824002311},
author = {Soumyadeep Hore and Jalal Ghadermazi and Ankit Shah and Nathaniel D. Bastian},
keywords = {Network intrusion detection system (NIDS), Multistage AI-based NIDS, Malicious packet classifier, Anomaly detector, Novelty detector, Sequential deep neural networks, One-shot learning, Transfer learning},
abstract = {Ensuring the security and integrity of computer and network systems is of utmost importance in today’s digital landscape. Network intrusion detection systems (NIDS) play a critical role in continuously monitoring network traffic and identifying unauthorized or potentially malicious activities that could compromise the confidentiality, availability, and integrity of these systems. However, traditional NIDS face a daunting challenge in effectively adapting to the evolving tactics of cyber attackers. To address this challenge, we propose a multistage artificial intelligence enabled framework for intrusion detection in network traffic, capable of handling zero-day, out-of-distribution, and adversarial evasion attacks. Our framework comprises three sequential deep neural network (DNN) architectures: one for the classifier and two for specific autoencoders, designed to effectively detect both known attack patterns and novel, previously unseen samples. We introduce an innovative transfer learning technique where specific combinations of neurons and layers in the DNN architectures are frozen during one-shot learning to enhance the framework’s robustness to novel attacks. To validate the effectiveness of our framework, we conducted extensive experimentation using publicly available benchmark intrusion detection data sets. Leveraging the one-shot learning approach in the transfer learning component of the framework, we demonstrate continuous improvement in detection accuracy for both known and novel network traffic patterns. The results demonstrate the effectiveness of the multiple stages in the framework by achieving, on average, 98.5% accuracy in detecting various attacks.}
}"
,AI-enhanced resilience in power systems: Adversarial deep learning for robust short-term voltage stability assessment under cyber-attacks,,2025,https://www.sciencedirect.com/science/article/abs/pii/S0960077925004199,Elsevier,  ,,,,,,,"@article{LI2025116406,
title = {AI-enhanced resilience in power systems: Adversarial deep learning for robust short-term voltage stability assessment under cyber-attacks},
journal = {Chaos, Solitons & Fractals},
volume = {196},
pages = {116406},
year = {2025},
issn = {0960-0779},
doi = {https://doi.org/10.1016/j.chaos.2025.116406},
url = {https://www.sciencedirect.com/science/article/pii/S0960077925004199},
author = {Yang Li and Shitu Zhang and Yuanzheng Li},
keywords = {Power system, Short-term voltage stability, Adversarial deep learning, Graph Attention Network, AI-based cyber resilience, Smart grid cybersecurity, Resilient control strategy},
abstract = {In the era of Industry 4.0, ensuring the resilience of cyber-physical systems against sophisticated cyber threats is increasingly critical. This study proposes a pioneering AI-based control framework that enhances short-term voltage stability assessments (STVSA) in power systems under complex composite cyber-attacks. First, by incorporating white-box and black-box adversarial attacks with Denial-of-Service (DoS) perturbations during training, composite adversarial attacks are implemented. Second, the application of Spectral Normalized Conditional Wasserstein Generative Adversarial Network with Gradient Penalty (SNCWGAN-GP) and Fast Gradient Sign Method (FGSM) strengthens the model's resistance to adversarial disturbances, improving data quality and training stability. Third, an assessment model based on Long Short-Term Memory (LSTM)-enhanced Graph Attention Network (L-GAT) is developed to capture dynamic relationships between the post-fault dynamic trajectories and electrical grid topology. Experimental results on the IEEE 39-bus test system demonstrate the efficacy and superiority of the proposed method in composite cyber-attack scenarios. This contribution is pivotal to advancing AI-based resilient control strategies for nonlinear dynamical systems, marking a substantial enhancement in the security of cyber-physical systems.}
}"
,"A meta-survey of adversarial attacks against artificial intelligence algorithms, including diffusion models",,2025,https://www.sciencedirect.com/science/article/pii/S0925231225019034,Elsevier,,,,,,,,"@article{PAWLICKI2025131231,
title = {A meta-survey of adversarial attacks against artificial intelligence algorithms, including diffusion models},
journal = {Neurocomputing},
volume = {653},
pages = {131231},
year = {2025},
issn = {0925-2312},
doi = {https://doi.org/10.1016/j.neucom.2025.131231},
url = {https://www.sciencedirect.com/science/article/pii/S0925231225019034},
author = {Marek Pawlicki and Aleksandra Pawlicka and Rafał Kozik and Michał Choraś},
keywords = {Adversarial attacks, Artificial intelligence, Deep learning},
abstract = {Deep neural networks have revolutionized artificial intelligence, solving complex issues in areas like healthcare or law enforcement and security. However, they are susceptible to adversarial attacks where small data manipulations can compromise system reliability and security. This paper conducts an umbrella review of the literature on these attacks, synthesizing results from various systematic reviews to assess attack strategies, defense effectiveness, and research gaps. Guided by the PICO framework, this review categorizes and examines adversarial attacks, identifying key challenges in the field. The review finds that even though adversarial vulnerabilities were first explored in computer vision, analogous threats have expanded to domains like graph neural networks, natural language processing, federated learning, and text-to-image models. Despite varied attack surfaces, commonalities can be found.}
}"
,AI for cyber-security risk: harnessing AI for automatic generation of company-specific cybersecurity risk profiles,,2025,https://www.sciencedirect.com/org/science/article/abs/pii/S2056496125000066,Elsevier,,,,,,,,"@article{SCHREIBER2025520,
title = {AI for cyber-security risk: harnessing AI for automatic generation of company-specific cybersecurity risk profiles},
journal = {Information and Computer Security},
volume = {33},
number = {4},
pages = {520-546},
year = {2025},
issn = {2056-4961},
doi = {https://doi.org/10.1108/ICS-08-2024-0177},
url = {https://www.sciencedirect.com/science/article/pii/S2056496125000066},
author = {Amir Schreiber and Ilan Schreiber},
keywords = {Cybersecurity risks, AI, Gen-AI, Generative AI, AI risks},
abstract = {Purpose
In the modern digital realm, artificial intelligence (AI) technologies create unprecedented opportunities and enhance tactical security operations. This study aims to address the gap in using AI to strategically produce holistic cybersecurity risk profiles.
Design/methodology/approach
This paper uses a rigorous AI-powered method to conduct cybersecurity risk profiles tailored to individual enterprises, investigating sources of threat and guiding defense strategies. This paper built a real working demo application based on real security databases and used it to build company-specific cybersecurity risk profiles.
Findings
This paper demonstrated a robust, automated process for developing tailored cybersecurity risk profiles in three case studies across different industries. The AI application produced coherent outputs, validated by experts as accurate.
Research limitations/implications
This study lays the groundwork for further research, allowing for refinement by integrating additional resources, such as near-real-time alerts from external or internal sources.
Practical implications
The escalating threat landscape highlights the need for organizations to adopt AI for cybersecurity management, leveraging tools that assist in defining and refining cybersecurity risk profiles to enhance defense measures.
Social implications
Using AI-generated cybersecurity risk profiles supports efforts to create a safer digital environment for organizations, their employees and their customers, aligning with the growing reliance on AI in daily life.
Originality/value
Unlike most papers, this paper uses an AI application to address contemporary challenges in creating holistic, non-tactical profiles that can be refined and contextualized by the organizations while achieving automation in key processes and integrating multiple resources.}
}"
,Security risks and countermeasures of adversarial attacks on AI-driven applications in 6G networks: A survey,,2024,https://www.sciencedirect.com/science/article/abs/pii/S108480452400208X,Elsevier,,,Survey,,,,,"@article{HOANG2024104031,
title = {Security risks and countermeasures of adversarial attacks on AI-driven applications in 6G networks: A survey},
journal = {Journal of Network and Computer Applications},
volume = {232},
pages = {104031},
year = {2024},
issn = {1084-8045},
doi = {https://doi.org/10.1016/j.jnca.2024.104031},
url = {https://www.sciencedirect.com/science/article/pii/S108480452400208X},
author = {Van-Tam Hoang and Yared Abera Ergu and Van-Linh Nguyen and Rong-Guey Chang},
keywords = {6G networks, Adversarial attacks, Adversarial defenses, Deep neural network, AI-powered 6G applications, O-RAN vulnerabilities, Noise perturbation, Adversarial anomaly detection},
abstract = {The advent of sixth-generation (6G) networks is expected to start a new era in mobile networks, characterized by unprecedented high demands on dense connectivity, ultra-reliability, low latency, and high throughput. Artificial intelligence (AI) is at the forefront of this progress, optimizing and enabling intelligence for essential 6G functions such as radio resource allocation, slicing, service offloading, and mobility management. However, AI is subject to a wide range of security risks, most notably adversarial attacks. Recent studies, inspired by computer vision and natural language processing, show that adversarial attacks have significantly reduced performance and caused incorrect decisions in wireless communications, jeopardizing the perspective of transforming AI-based 6G core networks. This survey presents a thorough investigation into the landscape of adversarial attacks and defenses in the realm of AI-powered functions within classic wireless networks, open radio access networks (O-RAN), and 6G networks. Two key findings are as follows. First, by leveraging shared wireless networks, attackers can provide noise perturbation or signal sampling for interference, resulting in misclassification in AI-based channel estimation and signal classification. From these basic weaknesses, 6G introduces new threat vectors from AI-based core functionalities, such as malicious agents in federated learning-based service offloading and adversarial attacks on O-RAN near-real-time RIC (xApp). Second, adversarial training, trustworthy mmWave/Terahertz datasets, adversarial anomaly detection, and quantum technologies for adversarial defenses are the most promising strategies for mitigating the negative effects of the attacks. This survey also identifies possible future research topics for adversarial attacks and countermeasures in 6G AI-enabled technologies.}
}"
,The metaverse: Privacy and information security risks,,2025,https://www.sciencedirect.com/science/article/pii/S2667096825000552,Elsevier,,,,,,,,"@article{LAIZIBANEZ2025100373,
title = {The metaverse: Privacy and information security risks},
journal = {International Journal of Information Management Data Insights},
volume = {5},
number = {2},
pages = {100373},
year = {2025},
issn = {2667-0968},
doi = {https://doi.org/10.1016/j.jjimei.2025.100373},
url = {https://www.sciencedirect.com/science/article/pii/S2667096825000552},
author = {Héctor Laiz-Ibanez and Cristina Mendaña-Cuervo and Juan Luis {Carus Candas}},
keywords = {Metaverse, Security, Privacy, Risks, Countermeasures, Cybersecurity, Emerging technologies},
abstract = {The advent of the metaverse—a convergence of physical and virtual realities catalyzed by a spectrum of emerging technologies—heralds a new epoch in the digital era. As the metaverse unfolds its immense potential, it simultaneously reveals unprecedented privacy and information security risks. Understanding these risks is paramount, as the pose significant implications for user safety, data integrity, and the overall trustworthiness of the metaverse. Consequently, this paper conducts a Systematic Literature Review (SLR) to meticulously analyze these emerging risks. Utilizing the Population, Intervention, Comparison, Outcomes, Context (PICOC) method, the review examines 735 articles from four databases, distilling essential insights from 35 key studies. The review identifies major challenges, including vulnerabilities in AI and IoT integration, threats from surveillance capitalism, and insufficient user education on privacy risks. To address these issues, the study proposes strategies such as holistic security frameworks, privacy-first design principles, and multi-stakeholder collaboration. These findings provide actionable insights for navigating the intricate dynamics of the metaverse, fostering a secure and privacy-conscious digital ecosystem. The study’s contributions aim to guide academic discourse, inform industry practices, and influence future policy development. The contributions from this research are intended to stimulate further academic discourse and influence future practices and policy in the context of the metaverse.}
}"
,,,,,,,,,,,,,
,Polymorphic Adversarial DDoS attack on IDS using GAN,Ravi Chauhan; Shahram Shah Heydari,2020,https://ieeexplore.ieee.org/document/9297264,IEEE,,,Confrence,,,,,"@INPROCEEDINGS{9297264,
  author={Chauhan, Ravi and Shah Heydari, Shahram},
  booktitle={2020 International Symposium on Networks, Computers and Communications (ISNCC)}, 
  title={Polymorphic Adversarial DDoS attack on IDS using GAN}, 
  year={2020},
  volume={},
  number={},
  pages={1-6},
  keywords={Generators;Generative adversarial networks;Data models;Feature extraction;Training;Malware;Intrusion detection;Adversarial Attacks;Generative Adversarial Networks (GAN);IDS;DDoS attacks;Machine Learning},
  doi={10.1109/ISNCC49221.2020.9297264}}
"
,Multi-Layer Defense for AI-powered IDS: Ensemble Adversarial Training and Explainable Resilience to Evasion Attacks,Hanh P. Du; Minh Q. Tran; Tuyen T. Nguyen; Hoa N. Nguyen,2025,https://ieeexplore.ieee.org/document/11250565,IEEE,,,Confrence,,,,,"@INPROCEEDINGS{11250565,
  author={Du, Hanh P. and Tran, Minh Q. and Nguyen, Tuyen T. and Nguyen, Hoa N.},
  booktitle={2025 2nd International Conference On Cryptography And Information Security (VCRIS)}, 
  title={Multi-Layer Defense for AI-powered IDS: Ensemble Adversarial Training and Explainable Resilience to Evasion Attacks}, 
  year={2025},
  volume={},
  number={},
  pages={1-6},
  keywords={Training;Accuracy;Intrusion detection;Predictive models;NSL-KDD;Feature extraction;Robustness;Cryptography;Faces;Resilience;Adversarial Attacks;Adversarial Defense;Intrusion Detection;Feature Squeezing;Adversarial Transferability},
  doi={10.1109/VCRIS68011.2025.11250565}}"
,Robust Image Classification: Defensive Strategies against FGSM and PGD Adversarial Attacks,Hetvi Waghela; Jaydip Sen; Sneha Rakshit,2025,https://ieeexplore.ieee.org/document/10941671,IEEE,,,confrence,,,,,"@INPROCEEDINGS{10941671,
  author={Waghela, Hetvi and Sen, Jaydip and Rakshit, Sneha},
  booktitle={2024 Asian Conference on Intelligent Technologies (ACOIT)}, 
  title={Robust Image Classification: Defensive Strategies against FGSM and PGD Adversarial Attacks}, 
  year={2024},
  volume={},
  number={},
  pages={1-7},
  keywords={Training;Perturbation methods;Autoencoders;Neural networks;Computer architecture;Reliability theory;Robustness;Security;Image classification;Resilience;VGG16;Adversarial Attacks;Image Classification;FGSM;PGD;Adversarial Defense;Neural Networks;Machine Learning Security},
  doi={10.1109/ACOIT62457.2024.10941671}}
"
,Securing IoT Networks with Adversarial Learning: A Defense Framework Against Cyber Threats,Abdellah Zyane; Hamza Jamiri,2025,https://ieeexplore.ieee.org/document/11008253,IEEE,,,Confrence,,,,,"@INPROCEEDINGS{11008253,
  author={Zyane, Abdellah and Jamiri, Hamza},
  booktitle={2025 5th International Conference on Innovative Research in Applied Science, Engineering and Technology (IRASET)}, 
  title={Securing IoT Networks with Adversarial Learning: A Defense Framework Against Cyber Threats}, 
  year={2025},
  volume={},
  number={},
  pages={1-7},
  keywords={Training;Support vector machines;Deep learning;Intrusion detection;Feature extraction;Robustness;Adversarial machine learning;Decision trees;Computer security;Resilience;Adversarial Attacks;Machine Learning;Deep Learning;IoT Security;Fast Gradient Sign Method (FGSM);Projected Gradient Descent (PGD);Adversarial Training;Feature Squeezing;Intrusion Detection;Cybersecurity in IoT},
  doi={10.1109/IRASET64571.2025.11008253}}"
,Optimizing Cloud Security with Machine Learning: Predicting and Preventing Vulnerabilities in Distributed Systems,Hari Gupta; Aneeshkumar P Sundareswaran; Riya Walia; Sanghamithra Duggirala; Sekar Mylsamy; Abhishek Jain,2025,https://ieeexplore.ieee.org/document/11102411,IEEE,,,Confrence,,,,,"@INPROCEEDINGS{11102411,
  author={Gupta, Hari and Sundareswaran, Aneeshkumar P and Walia, Riya and Duggirala, Sanghamithra and Mylsamy, Sekar and Jain, Abhishek},
  booktitle={2025 International Conference on Networks and Cryptology (NETCRYPT)}, 
  title={Optimizing Cloud Security with Machine Learning: Predicting and Preventing Vulnerabilities in Distributed Systems}, 
  year={2025},
  volume={},
  number={},
  pages={1598-1602},
  keywords={Support vector machines;Accuracy;Machine learning algorithms;Cloud computing security;Heuristic algorithms;Reinforcement learning;Nearest neighbor methods;Prediction algorithms;Security;Random forests;Cloud security;machine learning;distributed systems;vulnerability detection;anomaly detection;reinforcement learning;threat intelligence;predictive analytics},
  doi={10.1109/NETCRYPT65877.2025.11102411}}"
,Supervised Machine Learning for Cloud Security,Saurabh Singhal; Rishabh Srivastava; R Shyam; Deepak Mangal,2023,https://ieeexplore.ieee.org/document/10112078,IEEE,,,Confrence,,,,,"@INPROCEEDINGS{10112078,
  author={Singhal, Saurabh and Srivastava, Rishabh and Shyam, R and Mangal, Deepak},
  booktitle={2023 6th International Conference on Information Systems and Computer Networks (ISCON)}, 
  title={Supervised Machine Learning for Cloud Security}, 
  year={2023},
  volume={},
  number={},
  pages={1-5},
  keywords={Training;Service function chaining;Computational modeling;Cloud computing security;Machine learning;Data models;Network function virtualization;Cloud Security;Machine Learning;Supervised Learning;UNSW dataset;ISOT dataset},
  doi={10.1109/ISCON57294.2023.10112078}}"
,Adversarial Machine Learning for Network Intrusion Detection Systems: A Comprehensive Survey,Ke He; Dan Dongseong Kim; Muhammad Rizwan Asghar,2023,https://ieeexplore.ieee.org/abstract/document/10005100,IEEE,,,,,,,,"@ARTICLE{10005100,
  author={He, Ke and Kim, Dan Dongseong and Asghar, Muhammad Rizwan},
  journal={IEEE Communications Surveys & Tutorials}, 
  title={Adversarial Machine Learning for Network Intrusion Detection Systems: A Comprehensive Survey}, 
  year={2023},
  volume={25},
  number={1},
  pages={538-566},
  keywords={Feature extraction;Adversarial machine learning;Taxonomy;Task analysis;Monitoring;Internet of Things;Deep learning;NIDS;adversarial attacks;deep learning;cybersecurity},
  doi={10.1109/COMST.2022.3233793}}
"
,,,,,,,,,,,,,
,https://github.com/Huzi1080/CSM-Research-Paper/blob/main/README.md,,,,,,,,,,,,
,,,,,,,,,,,,,
,https://carleton.ca/ngn/wp-content/uploads/The-Threat-of-Adversarial-Attacks-on-Machine-Learning-in-Network-Security-A-Survey.pdf,,,,,,,,,,,,